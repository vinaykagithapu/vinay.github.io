"use strict";(globalThis.webpackChunkvinay_portfolio=globalThis.webpackChunkvinay_portfolio||[]).push([[9669],{5892(e,n,s){s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"mlops/data-preparation/streaming-datasets","title":"Streaming Datasets","description":"Understanding Apache Kafka and Apache Flink for building real-time data pipelines and stream processing in ML workflows","source":"@site/docs/mlops/data-preparation/5-streaming-datasets.md","sourceDirName":"mlops/data-preparation","slug":"/mlops/data-preparation/streaming-datasets","permalink":"/docs/mlops/data-preparation/streaming-datasets","draft":false,"unlisted":false,"editUrl":"https://github.com/vinaykagithapu/vinaykagithapu.github.io/tree/main/docs/mlops/data-preparation/5-streaming-datasets.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Streaming Datasets","description":"Understanding Apache Kafka and Apache Flink for building real-time data pipelines and stream processing in ML workflows"},"sidebar":"tutorialSidebar","previous":{"title":"Data Cleaning and Transformation","permalink":"/docs/mlops/data-preparation/data-cleaning-transformation"},"next":{"title":"DevOps","permalink":"/docs/category/devops"}}');var a=s(4848),r=s(8453);const i={sidebar_position:5,title:"Streaming Datasets",description:"Understanding Apache Kafka and Apache Flink for building real-time data pipelines and stream processing in ML workflows"},l="Streaming Datasets",o={},d=[{value:"XYZShopSmart: The Real-Time Challenge",id:"xyzshopsmart-the-real-time-challenge",level:2},{value:"Why Streaming Matters for ML",id:"why-streaming-matters-for-ml",level:2},{value:"Apache Kafka",id:"apache-kafka",level:2},{value:"Key Features of Kafka",id:"key-features-of-kafka",level:3},{value:"Kafka Architecture",id:"kafka-architecture",level:3},{value:"XYZShopSmart&#39;s Kafka Setup",id:"xyzshopsmarts-kafka-setup",level:3},{value:"Apache Flink",id:"apache-flink",level:2},{value:"Key Features of Flink",id:"key-features-of-flink",level:3},{value:"Flink Processing Capabilities",id:"flink-processing-capabilities",level:3},{value:"How Kafka and Flink Work Together",id:"how-kafka-and-flink-work-together",level:2},{value:"XYZShopSmart&#39;s Streaming Pipeline",id:"xyzshopsmarts-streaming-pipeline",level:2},{value:"Choosing Between Streaming and Batch",id:"choosing-between-streaming-and-batch",level:2},{value:"Common Mistakes",id:"common-mistakes",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"What&#39;s Next",id:"whats-next",level:2}];function c(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"streaming-datasets",children:"Streaming Datasets"})}),"\n",(0,a.jsxs)(n.p,{children:["In the previous section, we explored data cleaning and transformation for batch data. Now let's dive into ",(0,a.jsx)(n.strong,{children:"streaming datasets"}),"\u2014data that arrives continuously in real-time rather than in fixed batches."]}),"\n",(0,a.jsx)(n.p,{children:"Modern ML systems often need to process data as it happens. User clicks, sensor readings, and transaction events flow continuously and require immediate processing to deliver timely insights. Streaming platforms like Apache Kafka and Apache Flink enable this real-time data flow."}),"\n",(0,a.jsx)(n.admonition,{title:"Key Insight",type:"tip",children:(0,a.jsx)(n.p,{children:"Batch processing handles data at rest; stream processing handles data in motion. Many production ML systems combine both approaches\u2014batch for training, streaming for inference."})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"xyzshopsmart-the-real-time-challenge",children:"XYZShopSmart: The Real-Time Challenge"}),"\n",(0,a.jsx)(n.p,{children:"XYZShopSmart's recommendation system worked well with nightly batch updates, but Maya noticed a problem. When a customer purchased a laptop at 10 AM, they continued seeing laptop recommendations until the next morning's batch refresh. Customers complained about irrelevant suggestions, and the team suspected they were missing cross-sell opportunities for accessories."}),"\n",(0,a.jsx)(n.p,{children:"The data engineering team analyzed the issue. Their ETL pipelines processed clickstream and purchase data once daily\u2014extracting from web analytics, transforming in Spark, and loading to the Data Lake. By the time Maya's model retrained, customer intent had already shifted. They needed a streaming architecture to capture and process user behavior in real-time, feeding fresh signals to the recommendation engine within seconds of each interaction."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"why-streaming-matters-for-ml",children:"Why Streaming Matters for ML"}),"\n",(0,a.jsx)(n.p,{children:"Streaming datasets power scenarios where immediate insights drive business value. For XYZShopSmart, real-time processing means:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Updating recommendations instantly after a purchase"}),"\n",(0,a.jsx)(n.li,{children:"Detecting abandoned carts before customers leave"}),"\n",(0,a.jsx)(n.li,{children:"Personalizing homepage content based on current session behavior"}),"\n",(0,a.jsx)(n.li,{children:"Triggering alerts when unusual patterns emerge"}),"\n"]}),"\n",(0,a.jsx)(n.mermaid,{value:'flowchart LR\n    subgraph Sources["XYZShopSmart Sources"]\n        direction LR\n        WEB[Web Clickstream]\n        APP[Mobile App Events]\n    end\n    \n    subgraph Streaming["Stream Processing"]\n        KAFKA[Apache Kafka]\n        FLINK[Apache Flink]\n        DB[(Product<br/>Catalog)]\n    end\n    \n    subgraph Output["Real-Time Output"]\n        REC[Recommendation<br/>Engine]\n        DASH[Analytics<br/>Dashboard]\n    end\n    \n    Sources --\x3e KAFKA\n    KAFKA --\x3e FLINK\n    DB --\x3e FLINK\n    FLINK --\x3e REC\n    FLINK --\x3e DASH\n    \n    style Sources fill:#4A90A4,stroke:#2C5F6E,color:#fff\n    style Streaming fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style Output fill:#7B68A6,stroke:#4E4272,color:#fff'}),"\n",(0,a.jsx)(n.p,{children:"A streaming architecture captures user events via Apache Kafka, processes them through Apache Flink (enriched with product data from the existing catalog), and delivers real-time signals to both the recommendation engine and analytics dashboards."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"apache-kafka",children:"Apache Kafka"}),"\n",(0,a.jsx)(n.p,{children:"Apache Kafka is a distributed streaming platform for building real-time data pipelines and applications. It acts as a high-throughput message broker that reliably transports data between systems at scale."}),"\n",(0,a.jsx)(n.h3,{id:"key-features-of-kafka",children:"Key Features of Kafka"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"High-Throughput Data Streaming"}),": Manages real-time data streams with low-latency processing, handling millions of events per second"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Scalability for Massive Workloads"}),": Easily scales horizontally by adding more brokers to the cluster"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Fault-Tolerant Messaging"}),": Ensures reliable message delivery with replication and durability across multiple nodes"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Distributed Architecture for Flexibility"}),": Decouples producers and consumers, making it flexible for diverse use cases"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"kafka-architecture",children:"Kafka Architecture"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Component"}),(0,a.jsx)(n.th,{children:"Purpose"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Producers"})}),(0,a.jsx)(n.td,{children:"Applications that publish messages to Kafka topics"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Topics"})}),(0,a.jsx)(n.td,{children:"Named channels that organize messages by category"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Brokers"})}),(0,a.jsx)(n.td,{children:"Servers that store data and serve client requests"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Consumers"})}),(0,a.jsx)(n.td,{children:"Applications that subscribe to topics and process messages"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Consumer Groups"})}),(0,a.jsx)(n.td,{children:"Coordinate multiple consumers for parallel processing"})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"xyzshopsmarts-kafka-setup",children:"XYZShopSmart's Kafka Setup"}),"\n",(0,a.jsx)(n.p,{children:"XYZShopSmart configured Kafka to handle their real-time event flow:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Topic"}),(0,a.jsx)(n.th,{children:"Source"}),(0,a.jsx)(n.th,{children:"Events"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"user-clicks"})}),(0,a.jsx)(n.td,{children:"Web Analytics"}),(0,a.jsx)(n.td,{children:"Page views, product clicks, search queries"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"user-purchases"})}),(0,a.jsx)(n.td,{children:"Order Database"}),(0,a.jsx)(n.td,{children:"Completed transactions, cart additions"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"user-sessions"})}),(0,a.jsx)(n.td,{children:"Mobile App"}),(0,a.jsx)(n.td,{children:"App opens, session duration, navigation paths"})]})]})]}),"\n",(0,a.jsx)(n.p,{children:"Multiple consumer groups process these topics independently. The recommendation service consumes from all three topics to update user preferences. The analytics pipeline aggregates events for real-time dashboards. Kafka retains events for 7 days, enabling Maya to replay data when debugging model issues."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"apache-flink",children:"Apache Flink"}),"\n",(0,a.jsx)(n.p,{children:"Apache Flink is a stream processing framework for real-time event-driven applications and batch processing. While Kafka handles data transport, Flink handles data computation\u2014transforming, aggregating, and analyzing streams in real-time."}),"\n",(0,a.jsx)(n.h3,{id:"key-features-of-flink",children:"Key Features of Flink"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Event-Driven Processing"}),": Processes data as events occur with millisecond-level latency"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Stateful Stream Processing"}),": Maintains state during stream processing for complex data flows and aggregations"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Exactly-Once Semantics"}),": Guarantees each event is processed exactly once for accurate results, even during failures"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Seamless Integration with Big Data"}),": Works with data sources like Kafka, Hadoop, and NoSQL databases for real-time analytics"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Unified Batch and Stream Processing"}),": Handles both streaming and batch workloads with a single API"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"flink-processing-capabilities",children:"Flink Processing Capabilities"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Capability"}),(0,a.jsx)(n.th,{children:"Benefit"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Windowing"})}),(0,a.jsx)(n.td,{children:"Groups events by time or count for aggregation"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Complex Event Processing"})}),(0,a.jsx)(n.td,{children:"Detects patterns across event sequences"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"State Management"})}),(0,a.jsx)(n.td,{children:"Maintains computation state with fault tolerance"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Watermarks"})}),(0,a.jsx)(n.td,{children:"Handles out-of-order events in distributed systems"})]})]})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"how-kafka-and-flink-work-together",children:"How Kafka and Flink Work Together"}),"\n",(0,a.jsxs)(n.p,{children:["Kafka and Flink serve complementary roles in streaming architectures. Kafka handles ",(0,a.jsx)(n.strong,{children:"data ingestion and messaging"}),"\u2014reliably capturing and transporting events. Flink handles ",(0,a.jsx)(n.strong,{children:"data processing and analysis"}),"\u2014transforming streams into insights."]}),"\n",(0,a.jsx)(n.mermaid,{value:'flowchart LR\n    subgraph Ingestion["XYZShopSmart Events"]\n        DATA1[Clickstream]\n        DATA2[Purchases]\n    end\n    \n    subgraph Kafka["Apache Kafka"]\n        TOPIC1[user-clicks]\n        TOPIC2[user-purchases]\n    end\n    \n    subgraph Flink["Apache Flink"]\n        PROCESS[Combine and<br/>Aggregate Data]\n    end\n    \n    subgraph Output["Output"]\n        RESULT[Real-Time<br/>User Features]\n    end\n    \n    DATA1 --\x3e TOPIC1\n    DATA2 --\x3e TOPIC2\n    TOPIC1 --\x3e PROCESS\n    TOPIC2 --\x3e PROCESS\n    PROCESS --\x3e RESULT\n    \n    style Ingestion fill:#4A90A4,stroke:#2C5F6E,color:#fff\n    style Kafka fill:#E07B53,stroke:#A65535,color:#fff\n    style Flink fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style Output fill:#7B68A6,stroke:#4E4272,color:#fff'}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Apache Kafka"})," captures events from XYZShopSmart's web and mobile applications, organizing them into dedicated topics. ",(0,a.jsx)(n.strong,{children:"Apache Flink"})," consumes from these topics, joins streams with product catalog data, and computes real-time user features for the recommendation engine."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"xyzshopsmarts-streaming-pipeline",children:"XYZShopSmart's Streaming Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"XYZShopSmart implemented their streaming architecture alongside the existing batch ETL:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Event Capture"}),": Web and mobile apps publish user actions to Kafka topics as they occur"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Topic Routing"}),": Events flow to appropriate topics\u2014",(0,a.jsx)(n.code,{children:"user-clicks"}),", ",(0,a.jsx)(n.code,{children:"user-purchases"}),", ",(0,a.jsx)(n.code,{children:"user-sessions"})]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Stream Consumption"}),": Flink jobs subscribe to multiple topics simultaneously"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Stateful Aggregation"}),": Flink maintains rolling windows of user behavior\u2014clicks in the last 10 minutes, purchases in the last hour"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Catalog Enrichment"}),": Flink joins streaming events with product attributes from the curated zone of the Data Lake"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Feature Updates"}),": Computed features write to the Feature Store, making them available to the recommendation model"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dashboard Metrics"}),": Aggregated statistics stream to real-time dashboards for monitoring"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"This streaming layer complements their batch pipeline. Spark continues to process historical data nightly for model retraining, while Flink handles real-time feature updates for inference."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"choosing-between-streaming-and-batch",children:"Choosing Between Streaming and Batch"}),"\n",(0,a.jsx)(n.p,{children:"XYZShopSmart's data engineering team uses both approaches for different purposes:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Factor"}),(0,a.jsx)(n.th,{children:"Batch (Spark + Data Lake)"}),(0,a.jsx)(n.th,{children:"Streaming (Kafka + Flink)"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Use Case"})}),(0,a.jsx)(n.td,{children:"Model training, historical analysis"}),(0,a.jsx)(n.td,{children:"Real-time features, live recommendations"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Latency"})}),(0,a.jsx)(n.td,{children:"Hours (nightly jobs)"}),(0,a.jsx)(n.td,{children:"Seconds (continuous)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Data Sources"})}),(0,a.jsx)(n.td,{children:"CRM, order history, product catalog"}),(0,a.jsx)(n.td,{children:"Clickstream, session events"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Output"})}),(0,a.jsx)(n.td,{children:"Training datasets in curated zone"}),(0,a.jsx)(n.td,{children:"Feature Store updates"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Complexity"})}),(0,a.jsx)(n.td,{children:"Simpler orchestration"}),(0,a.jsx)(n.td,{children:"Requires state management"})]})]})]}),"\n",(0,a.jsxs)(n.p,{children:["Most ML systems use ",(0,a.jsx)(n.strong,{children:"hybrid architectures"}),". XYZShopSmart runs Spark for nightly model retraining using historical data from the Data Lake, while Flink computes real-time features that update the recommendation engine throughout the day."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"common-mistakes",children:"Common Mistakes"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Treating streams like batches"}),": Applying batch-oriented thinking to streaming systems leads to latency issues and missed events"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Ignoring exactly-once semantics"}),": Without proper guarantees, duplicate or missing events corrupt downstream data"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Underestimating state management"}),": Stateful stream processing requires careful checkpointing and recovery planning"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Over-partitioning Kafka topics"}),": Too many partitions add coordination overhead without proportional benefits"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Skipping backpressure handling"}),": When consumers fall behind, systems must handle the pressure gracefully or risk data loss"]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Apache Kafka handles data transport."})," As a distributed streaming platform, it provides high-throughput, fault-tolerant messaging that scales horizontally for massive event volumes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Apache Flink handles data computation."})," As a stream processing framework, it provides stateful processing with exactly-once semantics and millisecond latencies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Kafka and Flink complement each other."})," Kafka captures and organizes real-time events; Flink processes and analyzes them\u2014together they form a complete streaming architecture."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Streaming enables real-time ML features."})," For XYZShopSmart, streaming transforms recommendations from stale nightly updates to fresh, real-time personalization."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,a.jsx)(n.p,{children:"With batch ETL pipelines feeding the Data Lake and streaming pipelines delivering real-time features, XYZShopSmart has a complete data foundation. The next step is understanding how to engineer meaningful features from this data\u2014transforming raw events and records into inputs that help Maya's recommendation model learn patterns and make accurate predictions."}),"\n",(0,a.jsx)(n.admonition,{title:"Up Next",type:"info",children:(0,a.jsxs)(n.p,{children:["We'll explore ",(0,a.jsx)(n.strong,{children:"Feature Engineering"}),"\u2014the art of creating meaningful input variables from both batch and streaming data that help ML models discover patterns and make accurate predictions."]})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453(e,n,s){s.d(n,{R:()=>i,x:()=>l});var t=s(6540);const a={},r=t.createContext(a);function i(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);