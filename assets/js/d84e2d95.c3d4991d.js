"use strict";(globalThis.webpackChunkvinay_portfolio=globalThis.webpackChunkvinay_portfolio||[]).push([[8702],{4782(e,n,t){t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"mlops/mlops-fundamentals/mlops-architecture","title":"MLOps High-Level Architecture","description":"Understanding the complete MLOps architecture - from problem statement to model redeployment with data pipelines, ML workflows, and continuous monitoring","source":"@site/docs/mlops/mlops-fundamentals/7-mlops-architecture.md","sourceDirName":"mlops/mlops-fundamentals","slug":"/mlops/mlops-fundamentals/mlops-architecture","permalink":"/docs/mlops/mlops-fundamentals/mlops-architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/vinaykagithapu/vinaykagithapu.github.io/tree/main/docs/mlops/mlops-fundamentals/7-mlops-architecture.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"MLOps High-Level Architecture","description":"Understanding the complete MLOps architecture - from problem statement to model redeployment with data pipelines, ML workflows, and continuous monitoring"},"sidebar":"tutorialSidebar","previous":{"title":"Essential Tools for MLOps","permalink":"/docs/mlops/mlops-fundamentals/mlops-tools"},"next":{"title":"DevOps","permalink":"/docs/category/devops"}}');var s=t(4848),r=t(8453);const o={sidebar_position:7,title:"MLOps High-Level Architecture",description:"Understanding the complete MLOps architecture - from problem statement to model redeployment with data pipelines, ML workflows, and continuous monitoring"},l="MLOps High-Level Architecture",a={},d=[{value:"XYZShopSmart: Seeing the Big Picture",id:"xyzshopsmart-seeing-the-big-picture",level:2},{value:"The Complete Architecture",id:"the-complete-architecture",level:2},{value:"The Data Pipeline",id:"the-data-pipeline",level:2},{value:"XYZShopSmart&#39;s Data Pipeline",id:"xyzshopsmarts-data-pipeline",level:3},{value:"The Decision Point: Do We Need ML?",id:"the-decision-point-do-we-need-ml",level:2},{value:"When XYZShopSmart Chose ML",id:"when-xyzshopsmart-chose-ml",level:3},{value:"The ML Pipeline",id:"the-ml-pipeline",level:2},{value:"XYZShopSmart&#39;s ML Pipeline",id:"xyzshopsmarts-ml-pipeline",level:3},{value:"The Validation Gate",id:"the-validation-gate",level:2},{value:"The Production Loop",id:"the-production-loop",level:2},{value:"The Retraining Feedback Loop",id:"the-retraining-feedback-loop",level:3},{value:"MLOps Engineer Responsibilities Across the Architecture",id:"mlops-engineer-responsibilities-across-the-architecture",level:2},{value:"Data Handling",id:"data-handling",level:3},{value:"CI/CD and Monitoring",id:"cicd-and-monitoring",level:3},{value:"Scalability",id:"scalability",level:3},{value:"How XYZShopSmart&#39;s MLOps Engineer Contributes",id:"how-xyzshopsmarts-mlops-engineer-contributes",level:3},{value:"Architecture in Action: XYZShopSmart&#39;s Weekly Cycle",id:"architecture-in-action-xyzshopsmarts-weekly-cycle",level:2},{value:"Common Mistakes",id:"common-mistakes",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"What&#39;s Next",id:"whats-next",level:2}];function c(e){const n={admonition:"admonition",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"mlops-high-level-architecture",children:"MLOps High-Level Architecture"})}),"\n",(0,s.jsxs)(n.p,{children:["In the previous section, we explored the essential tools that power MLOps workflows. Now let's see how these tools fit together in a ",(0,s.jsx)(n.strong,{children:"complete architecture"})," that takes a problem statement through data processing, model development, and continuous monitoring."]}),"\n",(0,s.jsx)(n.p,{children:"Understanding this architecture helps teams design systems where each component has a clear purpose and connects seamlessly to the next."}),"\n",(0,s.jsx)(n.admonition,{title:"Key Insight",type:"tip",children:(0,s.jsx)(n.p,{children:"The MLOps architecture isn't linear \u2014 it's a loop. Data flows from collection to model deployment, but model monitoring feeds back into retraining, creating a self-improving system."})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"xyzshopsmart-seeing-the-big-picture",children:"XYZShopSmart: Seeing the Big Picture"}),"\n",(0,s.jsx)(n.p,{children:"After deploying their recommendation system, XYZShopSmart's team realized they needed a clear architectural blueprint. Different team members had built components in isolation \u2014 the data pipeline didn't align with feature engineering needs, and the monitoring system couldn't trigger retraining automatically. They needed a unified view of how all pieces connect."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-complete-architecture",children:"The Complete Architecture"}),"\n",(0,s.jsxs)(n.p,{children:["The MLOps architecture consists of three interconnected tracks: the ",(0,s.jsx)(n.strong,{children:"Data Pipeline"}),", the ",(0,s.jsx)(n.strong,{children:"ML Pipeline"}),", and the ",(0,s.jsx)(n.strong,{children:"Production Loop"}),". Each track handles specific responsibilities while feeding into the next."]}),"\n",(0,s.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Problem["Problem Statement"]\n        PS[Define Problem]\n    end\n    \n    subgraph DataPipeline["Data Pipeline"]\n        DC[Data Collection]\n        DI[Data Ingestion]\n        DT[Data Transformation<br/>& Cleaning]\n        DA[Data Analysis]\n        DV[Data Visualization]\n    end\n    \n    subgraph Decision1["Decision Point"]\n        Q1{Do we need ML<br/>for this problem?}\n    end\n    \n    subgraph MLPipeline["ML Pipeline"]\n        FE[Feature Engineering]\n        ME[Model Exploration]\n        MB[Model Building]\n        MT[Model Training]\n        MEval[Model Evaluation]\n    end\n    \n    subgraph Decision2["Validation"]\n        Q2{Does the model<br/>solve the problem?}\n    end\n    \n    subgraph Production["Production Loop"]\n        MM[Model Monitoring<br/>& Debugging]\n        MR[Model Redeployed]\n    end\n    \n    PS --\x3e DC\n    DC --\x3e DI\n    DI --\x3e DT\n    DT --\x3e DA\n    DA --\x3e DV\n    DV --\x3e Q1\n    \n    Q1 --\x3e|No| PS\n    Q1 --\x3e|Yes / Maybe| FE\n    \n    FE --\x3e ME\n    ME --\x3e MB\n    MB --\x3e MT\n    MT --\x3e MEval\n    MEval --\x3e Q2\n    \n    Q2 --\x3e|No| PS\n    Q2 --\x3e|Yes| MM\n    \n    MM --\x3e MR\n    MR -.->|Data for Retraining| FE\n    \n    style PS fill:#4A90A4,stroke:#2C5F6E,color:#fff\n    style DC fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style DI fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style DT fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style DA fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style DV fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style FE fill:#7B68A6,stroke:#4E4272,color:#fff\n    style ME fill:#7B68A6,stroke:#4E4272,color:#fff\n    style MB fill:#7B68A6,stroke:#4E4272,color:#fff\n    style MT fill:#7B68A6,stroke:#4E4272,color:#fff\n    style MEval fill:#7B68A6,stroke:#4E4272,color:#fff\n    style MM fill:#E07B53,stroke:#A65535,color:#fff\n    style MR fill:#E07B53,stroke:#A65535,color:#fff\n    style Q1 fill:#F5A623,stroke:#C4841D,color:#fff\n    style Q2 fill:#F5A623,stroke:#C4841D,color:#fff'}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-data-pipeline",children:"The Data Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"The Data Pipeline prepares raw information for machine learning. Every ML project starts here, regardless of the algorithm used later."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Collection"})," gathers raw data from various sources \u2014 databases, APIs, user interactions, and external systems."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Ingestion"})," moves collected data into a centralized storage system where it can be processed."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Transformation and Cleaning"})," standardizes formats, handles missing values, removes duplicates, and addresses outliers."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Analysis"})," explores patterns, distributions, and relationships within the cleaned data."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Visualization"})," presents findings through charts and dashboards that inform modeling decisions."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"xyzshopsmarts-data-pipeline",children:"XYZShopSmart's Data Pipeline"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Collection pulls user clickstream data, purchase history, and product catalog from three sources"}),"\n",(0,s.jsx)(n.li,{children:"Ingestion streams data into a data lake using Apache Kafka"}),"\n",(0,s.jsx)(n.li,{children:"Transformation jobs run nightly in Spark, outputting clean tables"}),"\n",(0,s.jsx)(n.li,{children:"Analysis notebooks explore user behavior patterns weekly"}),"\n",(0,s.jsx)(n.li,{children:"Visualization dashboards show data health metrics to the team"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-decision-point-do-we-need-ml",children:"The Decision Point: Do We Need ML?"}),"\n",(0,s.jsxs)(n.p,{children:["Not every problem requires machine learning. After analyzing the data, teams should ask: ",(0,s.jsx)(n.strong,{children:"Does this problem actually need ML, or would simpler approaches work?"})]}),"\n",(0,s.jsxs)(n.p,{children:["If the answer is ",(0,s.jsx)(n.strong,{children:"No"}),", return to the problem statement and refine it \u2014 perhaps the solution is a rule-based system or a simple statistical approach."]}),"\n",(0,s.jsxs)(n.p,{children:["If the answer is ",(0,s.jsx)(n.strong,{children:"Yes"})," or ",(0,s.jsx)(n.strong,{children:"Maybe"}),", proceed to the ML Pipeline with the prepared data."]}),"\n",(0,s.jsx)(n.h3,{id:"when-xyzshopsmart-chose-ml",children:"When XYZShopSmart Chose ML"}),"\n",(0,s.jsx)(n.p,{children:'The team initially considered rule-based recommendations ("show popular items"). Data analysis revealed that user preferences varied significantly by segment, purchase history, and browsing patterns. These complex relationships justified the ML investment.'}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-ml-pipeline",children:"The ML Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"The ML Pipeline transforms prepared data into a trained, validated model ready for production."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Feature Engineering"})," creates meaningful input variables from raw data \u2014 combining, transforming, and encoding features that help models learn patterns."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Exploration"})," researches and prototypes candidate algorithms to find approaches suited to the problem."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Building"})," implements the selected algorithms with proper architecture and hyperparameters."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Training"})," fits models to training data while tracking experiments."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Evaluation"})," measures performance against baselines and validates that the model solves the original problem."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"xyzshopsmarts-ml-pipeline",children:"XYZShopSmart's ML Pipeline"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Feature Engineering creates 50+ features: user embeddings, item popularity scores, time-based patterns"}),"\n",(0,s.jsx)(n.li,{children:"Model Exploration tests collaborative filtering, content-based, and hybrid approaches"}),"\n",(0,s.jsx)(n.li,{children:"Model Building implements a neural collaborative filtering architecture"}),"\n",(0,s.jsx)(n.li,{children:"Training runs on GPU cluster with MLflow tracking every experiment"}),"\n",(0,s.jsx)(n.li,{children:"Evaluation compares against random baseline and existing business rules"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-validation-gate",children:"The Validation Gate"}),"\n",(0,s.jsxs)(n.p,{children:["After model evaluation, teams face a critical question: ",(0,s.jsx)(n.strong,{children:"Does this model actually solve the problem statement?"})]}),"\n",(0,s.jsxs)(n.p,{children:["If ",(0,s.jsx)(n.strong,{children:"No"}),", the model doesn't meet requirements. Return to the problem statement \u2014 perhaps requirements need refinement, or the data pipeline needs improvements before another ML iteration."]}),"\n",(0,s.jsxs)(n.p,{children:["If ",(0,s.jsx)(n.strong,{children:"Yes"}),", the model is ready for production deployment and enters the production loop."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-production-loop",children:"The Production Loop"}),"\n",(0,s.jsx)(n.p,{children:"The Production Loop keeps deployed models healthy and improves them over time."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Monitoring and Debugging"})," tracks model performance in production, watching for accuracy degradation, latency issues, and data drift. When problems arise, debugging tools help identify root causes."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Redeployment"})," pushes updated models to production after retraining. The redeployed model generates new data that feeds back into Feature Engineering, completing the loop."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"the-retraining-feedback-loop",children:"The Retraining Feedback Loop"}),"\n",(0,s.jsx)(n.mermaid,{value:"flowchart LR\n    PROD[Production Model] --\x3e MON[Monitor Performance]\n    MON --\x3e DRIFT{Drift Detected?}\n    DRIFT --\x3e|No| MON\n    DRIFT --\x3e|Yes| COLLECT[Collect New Data]\n    COLLECT --\x3e RETRAIN[Retrain Model]\n    RETRAIN --\x3e VALIDATE[Validate]\n    VALIDATE --\x3e DEPLOY[Redeploy]\n    DEPLOY --\x3e PROD\n    \n    style PROD fill:#5BA88F,stroke:#3D7A62,color:#fff\n    style MON fill:#E07B53,stroke:#A65535,color:#fff\n    style DRIFT fill:#F5A623,stroke:#C4841D,color:#fff\n    style COLLECT fill:#4A90A4,stroke:#2C5F6E,color:#fff\n    style RETRAIN fill:#7B68A6,stroke:#4E4272,color:#fff\n    style VALIDATE fill:#7B68A6,stroke:#4E4272,color:#fff\n    style DEPLOY fill:#5BA88F,stroke:#3D7A62,color:#fff"}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"mlops-engineer-responsibilities-across-the-architecture",children:"MLOps Engineer Responsibilities Across the Architecture"}),"\n",(0,s.jsx)(n.p,{children:"The MLOps Engineer supports the entire architecture with specialized skills in three key areas:"}),"\n",(0,s.jsx)(n.h3,{id:"data-handling",children:"Data Handling"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Collect, ingest, transform, clean, and analyze data"})," \u2014 ensuring the data pipeline produces high-quality inputs for ML. The MLOps Engineer builds and maintains the infrastructure that makes data flow reliably."]}),"\n",(0,s.jsx)(n.h3,{id:"cicd-and-monitoring",children:"CI/CD and Monitoring"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Build CI/CD systems and implement testing, monitoring, and debugging"})," \u2014 automating the path from code commit to production deployment. Continuous monitoring catches issues before they impact users."]}),"\n",(0,s.jsx)(n.h3,{id:"scalability",children:"Scalability"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Ensure ML model scalability"})," \u2014 designing infrastructure that handles traffic spikes, manages compute resources efficiently, and maintains performance as data volumes grow."]}),"\n",(0,s.jsx)(n.h3,{id:"how-xyzshopsmarts-mlops-engineer-contributes",children:"How XYZShopSmart's MLOps Engineer Contributes"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Responsibility"}),(0,s.jsx)(n.th,{children:"Implementation"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Data Handling"}),(0,s.jsx)(n.td,{children:"Airflow DAGs for ETL, Great Expectations for validation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CI/CD"}),(0,s.jsx)(n.td,{children:"GitLab pipelines, automated testing, ArgoCD deployments"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Monitoring"}),(0,s.jsx)(n.td,{children:"Prometheus metrics, Grafana dashboards, PagerDuty alerts"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Scalability"}),(0,s.jsx)(n.td,{children:"Kubernetes HPA, GPU auto-scaling, load balancing"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"architecture-in-action-xyzshopsmarts-weekly-cycle",children:"Architecture in Action: XYZShopSmart's Weekly Cycle"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monday"}),": Data Pipeline processes weekend user interactions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Tuesday"}),": Analysis dashboards flag unusual patterns"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Wednesday"}),": Feature Engineering incorporates new behavioral signals"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Thursday"}),": Automated training pipeline produces candidate models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Friday"}),": Validated models deploy via canary release"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Weekend"}),": Monitoring tracks performance; cycle repeats"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"common-mistakes",children:"Common Mistakes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Skipping the ML decision point"}),": Not every problem needs ML \u2014 validate the need before investing in complex solutions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Disconnected pipelines"}),": Data and ML pipelines built in isolation create handoff friction and data quality issues"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Missing the feedback loop"}),": Without retraining triggers, models degrade silently over time"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Ignoring the problem statement"}),": Technical teams focus on model accuracy while losing sight of the business problem"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Underinvesting in monitoring"}),": Production issues go undetected without comprehensive observability"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"The architecture forms a complete loop."})," Data flows from problem statement through collection, analysis, modeling, and back via monitoring and retraining."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Decision gates prevent wasted effort."}),' Asking "Do we need ML?" and "Does the model solve the problem?" ensures resources go to valuable work.']}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"MLOps Engineers enable the entire architecture."})," Through data handling, CI/CD, monitoring, and scalability, they keep every component running smoothly."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"The production loop drives continuous improvement."})," Monitoring and redeployment create a self-improving system that adapts to changing data patterns."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,s.jsx)(n.p,{children:"With a solid understanding of MLOps architecture, you're ready to apply these concepts in practice. The next sections will provide hands-on implementations of each architectural component."}),"\n",(0,s.jsx)(n.admonition,{title:"Up Next",type:"info",children:(0,s.jsx)(n.p,{children:"We'll dive into practical implementations, starting with setting up a complete version control workflow using Git and DVC for tracking code, data, and models together."})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453(e,n,t){t.d(n,{R:()=>o,x:()=>l});var i=t(6540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);